// Misc. ---------------------------------------------------------------------------

fn @cpu_atomic_add_i64(a: &mut i64, b: i64) -> i64 = atomic[i64](1, a, b, 7, "");
fn @cpu_atomic_add_i32(a: &mut i32, b: i32) -> i32 = cpu_atomic_add(a, b);
fn @cpu_atomic_min_i32(a: &mut i32, b: i32) -> i32 = cpu_atomic_min(a, b);
fn @cpu_atomic_max_i32(a: &mut i32, b: i32) -> i32 = cpu_atomic_max(a, b);
fn @cpu_atomic_add_f32(a: &mut f32, b: f32) -> f32 = atomic[f32](11, a, b, 7, "");

// Iterate over the bit that are set in a mask (assumes that mask != 0)
fn @cpu_one_bits(body: fn (i32) -> ()) {
    fn loop(mut mask: i32) -> () {
        let lane = cpu_ctz32(mask, true);
        @body(lane);
        mask &= mask - 1;
        if mask != 0 {
            loop(mask)
        }
    }
    loop
}

// Performs a horizontal reduction over vector lanes
fn @(?n) cpu_vector_reduce(value: f32, n: i32, op: fn (f32, f32) -> f32) -> f32 {
    if n >= 2 {
        let m = n / 2;
        cpu_vector_reduce(op(value, rv_shuffle(value, m)), m, op)
    } else {
        value
    }
}

// Prefetches a chunk of memory
fn @cpu_prefetch_bytes(ptr: &[u8], bytes: i32) -> () {
    for i in unroll_step(0, bytes, 64) {
        cpu_prefetch(&ptr(i),  0 /* read */, 3 /* closest locality */, 1 /* data */)
    }
}

// Returns the first vector lane index i for which value[i] == lane
fn @cpu_index_of(value: f32, lane: f32) -> i32 {
    cpu_ctz32(rv_ballot(value == lane), true)
}

// Vectorizes an arbitrary range
fn @vectorized_range(body: fn (i32, i32) -> ()) = @|vector_width: i32, a: i32, b: i32| {
    if vector_width == 1 {
        for i in range(a, b) {
            body(i, 1)
        }
    } else {
        let n_vec = round_down(b - a, vector_width);
        for i in range_step(a, a + n_vec, vector_width) {
            vectorize(vector_width, |j| @body(i + j, vector_width))
        }
        for i in range(a + n_vec, b) {
            @body(i, 1)
        }
    }
};

/// Will reduce based on the given operator
fn @cpu_reduce[T](n: i32, elem: fn (i32) -> T, op: fn (T, T) -> T) -> T {
    if n <= 0 { return(undef[T]()) }
    if n <= 1 { return(elem(0)) }

    if n < 10000 {
        let mut sum = @elem(0);
        for i in safe_unroll(1, n) {
            sum = @op(sum, @elem(i));
        }
        sum
    } else {
        // Hardcoded 8 threads
        let mut lane : [T * 8];
        let dn = round_up(n, 8) / 8;
        for i in parallel(8, 0, 8) {
            let s = i       * dn;
            let e = (i + 1) * dn;
            
            // Maybe vectorize as well?
            let mut isum = @elem(s);
            for j in safe_unroll(s + 1, e) {
                isum = @op(isum, @elem(j));
            }
            
            lane(i) = isum;
        }

        let mut sum = lane(0);
        for i in safe_unroll(1, 8) {
            sum = @op(sum, lane(i));
        }
        sum
    }
}

fn @cpu_parallel_tiles(body: fn (i32, i32, i32, i32) -> ()) =
    @|width: i32, height: i32, tile_width: i32, tile_height: i32, num_cores: i32| {
    if num_cores == 1 {
        for ymin in range_step(0, height, tile_height) {
            for xmin in range_step(0, width, tile_width) {
                let xmax = if xmin + tile_width  < width  { xmin + tile_width  } else { width  };
                let ymax = if ymin + tile_height < height { ymin + tile_height } else { height };
                @body(xmin, ymin, xmax, ymax)
            }
        }
    } else {
        let num_tiles_x = round_up(width , tile_width)  / tile_width;
        let num_tiles_y = round_up(height, tile_height) / tile_height;
        let num_tiles = num_tiles_x * num_tiles_y;
        let tiles_div = make_fast_div(num_tiles_x as u32);
        for i in parallel(num_cores, 0, num_tiles) {
            let y = fast_div(tiles_div, i as u32) as i32;
            let x = i - num_tiles_x * y;
            let xmin = x * tile_width;
            let ymin = y * tile_height;
            let xmax = min(xmin + tile_width,  width);
            let ymax = min(ymin + tile_height, height);
            @body(xmin, ymin, xmax, ymax)
        }
    }
};